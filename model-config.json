{
  "default": "ollama-gpt-oss-20b",
  "models": {
    "ollama-gpt-oss-20b": {
      "provider": "ollama",
      "model": "gpt-oss:20b",
      "api_base": "http://host.docker.internal:11434",
      "temperature": 0.7,
      "max_tokens": 2048,
      "stream": true
    }
  }
}
